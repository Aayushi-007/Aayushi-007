{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": ".Convolutional_Neural_Networks-checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayushi-007/machine-learning/blob/main/_Convolutional_Neural_Networks_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDWb8jzkqI3"
      },
      "source": [
        "# Part 1: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAxVZg8kqI6"
      },
      "source": [
        "###  Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSTapDRkqI9"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "3otQrU4JWLej"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKUqkgGkqJI"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtwFbXyskqJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9767ac66-6e17-49d5-ec5a-3785220f0cd5"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test =to_categorical(y_test, num_classes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A1KfUskqJT"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMtSvqMdkqJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e828d067-a343-4764-fd0a-7e1ed8c12ace"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                12832     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,410\n",
            "Trainable params: 14,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aab-hxdkqJc"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWvDXQgkqJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087cda3b-716d-4999-8b3f-add78f6e2401"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 2.3154 - accuracy: 0.1086 - val_loss: 2.2863 - val_accuracy: 0.1406\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 2.3022 - accuracy: 0.1200 - val_loss: 2.2718 - val_accuracy: 0.1899\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.2874 - accuracy: 0.1313 - val_loss: 2.2581 - val_accuracy: 0.2265\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 2.2749 - accuracy: 0.1420 - val_loss: 2.2451 - val_accuracy: 0.2511\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.2621 - accuracy: 0.1538 - val_loss: 2.2320 - val_accuracy: 0.2697\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 2.2501 - accuracy: 0.1634 - val_loss: 2.2185 - val_accuracy: 0.2870\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.2397 - accuracy: 0.1750 - val_loss: 2.2044 - val_accuracy: 0.3061\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.2290 - accuracy: 0.1858 - val_loss: 2.1897 - val_accuracy: 0.3260\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.2170 - accuracy: 0.1965 - val_loss: 2.1744 - val_accuracy: 0.3455\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.2037 - accuracy: 0.2055 - val_loss: 2.1579 - val_accuracy: 0.3618\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.1903 - accuracy: 0.2132 - val_loss: 2.1410 - val_accuracy: 0.3798\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.1750 - accuracy: 0.2248 - val_loss: 2.1229 - val_accuracy: 0.3979\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.1636 - accuracy: 0.2320 - val_loss: 2.1045 - val_accuracy: 0.4134\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.1482 - accuracy: 0.2430 - val_loss: 2.0851 - val_accuracy: 0.4266\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.1366 - accuracy: 0.2460 - val_loss: 2.0655 - val_accuracy: 0.4387\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.1206 - accuracy: 0.2570 - val_loss: 2.0451 - val_accuracy: 0.4494\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.1051 - accuracy: 0.2638 - val_loss: 2.0243 - val_accuracy: 0.4624\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.0878 - accuracy: 0.2694 - val_loss: 2.0029 - val_accuracy: 0.4725\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.0775 - accuracy: 0.2762 - val_loss: 1.9813 - val_accuracy: 0.4824\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.0585 - accuracy: 0.2852 - val_loss: 1.9593 - val_accuracy: 0.4932\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.0426 - accuracy: 0.2921 - val_loss: 1.9369 - val_accuracy: 0.5056\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 2.0271 - accuracy: 0.2959 - val_loss: 1.9142 - val_accuracy: 0.5175\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 2.0158 - accuracy: 0.3003 - val_loss: 1.8915 - val_accuracy: 0.5309\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.9966 - accuracy: 0.3062 - val_loss: 1.8684 - val_accuracy: 0.5419\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.9777 - accuracy: 0.3157 - val_loss: 1.8446 - val_accuracy: 0.5523\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.9658 - accuracy: 0.3219 - val_loss: 1.8214 - val_accuracy: 0.5621\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.9469 - accuracy: 0.3265 - val_loss: 1.7977 - val_accuracy: 0.5720\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 1.9271 - accuracy: 0.3347 - val_loss: 1.7732 - val_accuracy: 0.5816\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.9126 - accuracy: 0.3397 - val_loss: 1.7491 - val_accuracy: 0.5920\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.8979 - accuracy: 0.3460 - val_loss: 1.7254 - val_accuracy: 0.6014\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.8822 - accuracy: 0.3534 - val_loss: 1.7015 - val_accuracy: 0.6116\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 1.8645 - accuracy: 0.3592 - val_loss: 1.6778 - val_accuracy: 0.6204\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 1.8507 - accuracy: 0.3631 - val_loss: 1.6543 - val_accuracy: 0.6287\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 1.8343 - accuracy: 0.3704 - val_loss: 1.6314 - val_accuracy: 0.6367\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.8204 - accuracy: 0.3766 - val_loss: 1.6084 - val_accuracy: 0.6456\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.8027 - accuracy: 0.3803 - val_loss: 1.5854 - val_accuracy: 0.6532\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.7902 - accuracy: 0.3841 - val_loss: 1.5631 - val_accuracy: 0.6592\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.7728 - accuracy: 0.3928 - val_loss: 1.5409 - val_accuracy: 0.6675\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.7576 - accuracy: 0.3986 - val_loss: 1.5189 - val_accuracy: 0.6729\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.7439 - accuracy: 0.4017 - val_loss: 1.4971 - val_accuracy: 0.6787\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 1.7297 - accuracy: 0.4077 - val_loss: 1.4757 - val_accuracy: 0.6833\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.7159 - accuracy: 0.4117 - val_loss: 1.4552 - val_accuracy: 0.6897\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.7028 - accuracy: 0.4162 - val_loss: 1.4348 - val_accuracy: 0.6934\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 1.6918 - accuracy: 0.4212 - val_loss: 1.4151 - val_accuracy: 0.6982\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.6737 - accuracy: 0.4273 - val_loss: 1.3951 - val_accuracy: 0.7024\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 1.6649 - accuracy: 0.4277 - val_loss: 1.3759 - val_accuracy: 0.7075\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.6468 - accuracy: 0.4346 - val_loss: 1.3565 - val_accuracy: 0.7126\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.6357 - accuracy: 0.4390 - val_loss: 1.3381 - val_accuracy: 0.7179\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.6257 - accuracy: 0.4408 - val_loss: 1.3195 - val_accuracy: 0.7214\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 1.6141 - accuracy: 0.4485 - val_loss: 1.3020 - val_accuracy: 0.7256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2dc9eec190>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprccy28kqJn"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74OuyWUkkqJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d6d3f1-6a80-4835-d558-2c5b8549115b"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.3274459838867188\n",
            "Test accuracy: 0.10090000182390213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMO1hxHkqJw"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHv0D_xhkqJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "49c20b4a-75dd-4284-ec70-0b2557baa053"
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.imshow(x_test[122].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "li=[0.5, 0,0.4, 0,0,0]\n",
        "li=np.array(li)\n",
        "thresholded = (li>=0.5)*1\n",
        "thresholded "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFYYp7JEaHoj",
        "outputId": "074ef7bd-e4af-4eec-93c4-8d1bd618a22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7ffffzwBkqJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eac108c-8f35-490c-a6b2-4294d8e4acab"
      },
      "source": [
        "import numpy as np\n",
        "prediction = model.predict(x_test[122:123])\n",
        "print('Prediction Score:\\n',prediction[0])\n",
        "thresholded = (prediction>0.5)*1\n",
        "print('\\nThresholded Score:\\n',thresholded[0])\n",
        "print('\\nPredicted Digit:\\n',np.where(thresholded == 1)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Score:\n",
            " [0.08421844 0.09510391 0.10316563 0.08681452 0.10299142 0.1070662\n",
            " 0.1075852  0.10420044 0.11079314 0.09806109]\n",
            "\n",
            "Thresholded Score:\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "Predicted Digit:\n",
            " []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKT5OJSVkqJ8"
      },
      "source": [
        "# Part 2: Applications of Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzUY5QxykqJ_"
      },
      "source": [
        "###  MobileNet Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVPVmwIZkqKA"
      },
      "source": [
        "model = MobileNet(input_shape=None, alpha=0.25, depth_multiplier=1, dropout=1e-3, \n",
        "                                 include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGjhRRmkqKI"
      },
      "source": [
        "###  Classify images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTFWBD9FkqKK"
      },
      "source": [
        "# Write the image name below\n",
        "\n",
        "img_path = '.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:\\n', decode_predictions(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvQWG_8kqKQ"
      },
      "source": [
        "###  Extract CNN features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rT0iPnxkqKS"
      },
      "source": [
        "features = model.predict(x)\n",
        "print('\\nFeature Shape:\\n',features.shape)\n",
        "print('\\nFeatures:\\n',features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYHHR_bskqKY"
      },
      "source": [
        "###  Extract features from an arbitrary intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOrIUA2DkqKb"
      },
      "source": [
        "model_minimal = Model(input=model.input, output=model.get_layer('conv_dw_2_relu').output)\n",
        "\n",
        "conv_dw_2_relu_features = model_minimal.predict(x)\n",
        "print('Features of conv_dw_2_relu:',conv_dw_2_relu_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPYajJZkqKh"
      },
      "source": [
        "### You can extract these features and use the base network as a feature extractor for your problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5z5cFn5kqKj"
      },
      "source": [
        "# Part 3: Deep Convolution Layer Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjr6DcimkqKm"
      },
      "source": [
        "import matplotlib as mp\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOMgk22xkqKr"
      },
      "source": [
        "### Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6PBNav6kqKt"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-nifFGhkqKy"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9LkN_paDkqKz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784],name=\"x-in\")\n",
        "true_y = tf.placeholder(tf.float32, [None, 10],name=\"y-in\")\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "hidden_1 = slim.conv2d(x_image,5,[5,5])\n",
        "pool_1 = slim.max_pool2d(hidden_1,[2,2])\n",
        "hidden_2 = slim.conv2d(pool_1,5,[5,5])\n",
        "pool_2 = slim.max_pool2d(hidden_2,[2,2])\n",
        "hidden_3 = slim.conv2d(pool_2,20,[5,5])\n",
        "hidden_3 = slim.dropout(hidden_3,keep_prob)\n",
        "out_y = slim.fully_connected(slim.flatten(hidden_3),10,activation_fn=tf.nn.softmax)\n",
        "\n",
        "cross_entropy = -tf.reduce_sum(true_y*tf.log(out_y))\n",
        "correct_prediction = tf.equal(tf.argmax(out_y,1), tf.argmax(true_y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEodGsOUkqK5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPBduFekqK6"
      },
      "source": [
        "batchSize = 50\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "for i in range(1001):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    sess.run(train_step, feed_dict={x:batch[0],true_y:batch[1], keep_prob:0.5})\n",
        "    if i % 100 == 0 and i != 0:\n",
        "        trainAccuracy = sess.run(accuracy, feed_dict={x:batch[0],true_y:batch[1], keep_prob:1.0})\n",
        "        print(\"step %d, training accuracy %g\"%(i, trainAccuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTeqbaJkqLA"
      },
      "source": [
        "### Testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-JBoLBAkqLB"
      },
      "source": [
        "testAccuracy = sess.run(accuracy, feed_dict={x:mnist.test.images,true_y:mnist.test.labels, keep_prob:1.0})\n",
        "print(\"test accuracy %g\"%(testAccuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2BhkZBskqLI"
      },
      "source": [
        "### Get activation values and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8DOheo-hkqLJ"
      },
      "source": [
        "def getActivations(layer,stimuli):\n",
        "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
        "    plotNNFilter(units)\n",
        "    \n",
        "def plotNNFilter(units):\n",
        "    filters = units.shape[3]\n",
        "    plt.figure(1, figsize=(20,20))\n",
        "    n_columns = 6\n",
        "    n_rows = math.ceil(filters / n_columns) + 1\n",
        "    for i in range(filters):\n",
        "        plt.subplot(n_rows, n_columns, i+1)\n",
        "        plt.title('Filter ' + str(i))\n",
        "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkoaARCnkqLO"
      },
      "source": [
        "### Input Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUdOll7bkqLQ"
      },
      "source": [
        "imageToUse = mnist.test.images[0]\n",
        "plt.imshow(np.reshape(imageToUse,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZ5UZDkkqLV"
      },
      "source": [
        "### Activation in Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5dxXfvPkqLX"
      },
      "source": [
        "getActivations(hidden_1,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9gNAvrkqLd"
      },
      "source": [
        "### Activation in Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlb3LGrWkqLe"
      },
      "source": [
        "getActivations(hidden_2,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqGvOEkkqLl"
      },
      "source": [
        "### Activation in Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmkgnW5ckqLo"
      },
      "source": [
        "getActivations(hidden_3,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awq5VogkqLt"
      },
      "source": [
        "# Part 4: Design Choices in Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGnsygzkqLv"
      },
      "source": [
        "## Influence of convolution size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVCTsJPkqLy"
      },
      "source": [
        "### Model with (3 x 3) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5wWkLbAkqL0"
      },
      "source": [
        "K.clear_session()\n",
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAuW0NOHkqL7"
      },
      "source": [
        "### Model with (7 x 7) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnphlXbvkqL8"
      },
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2WASoQkqMD"
      },
      "source": [
        "## Striding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h9XyTZKkqME"
      },
      "source": [
        "### Model with (7 x 7) Convolution with 2 Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K39I1weskqMF"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=2, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6_wR8GkqMK"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3kln95ykqMM"
      },
      "source": [
        "### Model with (7 x 7) Convolution with Same Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QinhffvkkqMO"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=1, padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLPfWDdYkqMT"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhAfYO0kqMV"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (2 x 2) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMSL5flZkqMW"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HsHtxt0kqMc"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (3 x 3) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w9kCVL7kqMe"
      },
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzV7LwepkqMn"
      },
      "source": [
        "### What are your findings?"
      ]
    }
  ]
}