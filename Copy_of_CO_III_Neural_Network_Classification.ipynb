{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayushi-007/machine-learning/blob/main/Copy_of_CO_III_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "CO CST IMPLEMENTATION OF NEURAL NETWORK\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bDN6Un_6rAR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd25c660-25dc-4785-bbe5-b9fe67c2721b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "4c315184-017a-4060-b6e7-d7af2184033a"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab8b30f-0a01-4040-c6c5-3270e4e279c5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0827CT191001.pdf\n",
            " 20210103_143339.jpg\n",
            "'Aayushi balothiya (01) chem..pdf'\n",
            "'aayushi balothiya(CSO).pdf'\n",
            "'activity diagram minor.drawio'\n",
            "'activity diagram minor.jpg'\n",
            "'ADA CT-01.docx'\n",
            "'Amol Paliwal (0827CT191009).gdoc'\n",
            "'certificate 1.pdf'\n",
            "'certificate_20215006890867 (1).pdf'\n",
            " certificate_20215006890867-1.pdf\n",
            "'certificate_20215006890867 (2).pdf'\n",
            " certificate_20215006890867.pdf\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'Computer Workshop 306 Assignment.docx'\n",
            "'Computer Workshop 306 Assignment.gdoc'\n",
            "'Copy of 31. Tower of Hanoi Problem.mp4'\n",
            "'Copy of HTML Assignments 1.docx'\n",
            "'Copy of Linear_Regression_Sklearn.ipynb'\n",
            "'Customer Feedback (1).gform'\n",
            "'Customer Feedback.gform'\n",
            " custom_trainvalacc.png\n",
            " custom_trainvalloss.png\n",
            "'Cw1 Aayushi balothiya (0827CT191001).docx'\n",
            "'Cw2 Aayushi balothiya (0827ct191001).docx'\n",
            "'dataset1 (1).csv'\n",
            "'Dbms assign (0827CT191001).docx'\n",
            " diabetes.csv\n",
            "'Digital circuit Design,CS 3003, lab manual.gdoc'\n",
            "'Digital circuit Design,CS 3003, lab manual.pdf'\n",
            "'edx 1.pdf'\n",
            "'Example -2.gdoc'\n",
            "'Example No-1 (1).gdoc'\n",
            "'Example No-1 (2).gdoc'\n",
            "'Example No-1.gdoc'\n",
            "'faculty data (1).xlsx'\n",
            "'faculty data (2).xlsx'\n",
            "'faculty data.xlsx'\n",
            "'fee receipt june.docx'\n",
            "'frm_download_file (7).gdoc'\n",
            "'frm_download_file (7).pdf'\n",
            "'G8_eventsite (1).docx'\n",
            " G8_eventsite.docx\n",
            "'Getting started.pdf'\n",
            "'harshita minor project.doc'\n",
            "'HTML Assignments 1 (1).gdoc'\n",
            "'HTML Assignments 1 (2).gdoc'\n",
            "'HTML Assignments 1 (3).gdoc'\n",
            "'HTML Assignments 1 (4).gdoc'\n",
            "'HTML Assignments 1.gdoc'\n",
            "'IEEE_srs_template (2) (1).gdoc'\n",
            "'IEEE_srs_template (2) (2).gdoc'\n",
            "'IEEE_srs_template (2) (3).gdoc'\n",
            "'IEEE_srs_template (2).gdoc'\n",
            " IMG-20211225-WA0000.jpg\n",
            " IMG-20211226-WA0000.jpg\n",
            "'IP DNS Subnet Mask.pptx'\n",
            "'iwt and linux'\n",
            " javanotes5.pdf\n",
            " java.pptx\n",
            "'Joy of Giving Week.gform'\n",
            " Linear_Regression_Sklearn.ipynb\n",
            "'linux edx.pdf'\n",
            "'Linux Lab work (1).gdoc'\n",
            "'Linux Lab work.gdoc'\n",
            "'literatrure review.pdf'\n",
            "'literatur review.gdoc'\n",
            "'literture review'\n",
            "'minor paper.gdoc'\n",
            "'My first (OTT)'\n",
            "'operating system'\n",
            "'Operating System soln.pdf'\n",
            "'Operating System Tutorial.docx'\n",
            "'Operating System Tutorial.gdoc'\n",
            "'os ppt.gslides'\n",
            "'Os ppt.pptx'\n",
            "'OS sche..pdf'\n",
            " Resume_Aayushi_Balothiya_for_Aayushi_balothiya.pdf\n",
            "'Resume aayushi.pdf'\n",
            "'Sample_SRS (1).gdoc'\n",
            "'Sample_SRS (2).gdoc'\n",
            "'Sample_SRS (3).gdoc'\n",
            " Sample_SRS.gdoc\n",
            " Sample_SRS.pdf\n",
            "'Screenshot_20200814-144907_Samsung Internet.jpg'\n",
            " Screenshot_20210529-115115_YouTube.jpg\n",
            " Screenshot_20210529-141508_YouTube.jpg\n",
            " Screenshot_20210602-142718_Chrome.jpg\n",
            " Screenshot_20210811-122806_YouTube.jpg\n",
            " Screenshot_20211218-121207_Chrome.jpg\n",
            " toaz.info-verbal-ability-amp-reading-comprehension-for-cat-arun-sharmapdf-pr_ff1b957d8a06d7e59c4aa40df512a9d1.pdf\n",
            "'TOCLab Manual 2021 (1).gdoc'\n",
            "'TOCLab Manual 2021 (2).gdoc'\n",
            "'TOCLab Manual 2021.gdoc'\n",
            "'TOC_Practical_assessment_format (1).gdoc'\n",
            "'TOC_Practical_assessment_format (2).gdoc'\n",
            "'TOC_Practical_assessment_format (3).gdoc'\n",
            " TOC_Practical_assessment_format.gdoc\n",
            "'TOC unit 1 and 2 (1).gslides'\n",
            "'TOC unit 1 and 2 (2).gslides'\n",
            "'TOC unit 1 and 2.gslides'\n",
            "'traveler advisory G4.gdoc'\n",
            " unit1.gdoc\n",
            "'Untitled Diagram.jpg'\n",
            "'Untitled form (1).gform'\n",
            "'Untitled form (2).gform'\n",
            "'Untitled form.gform'\n",
            "'Untitled form (Responses).gsheet'\n",
            "'Urmi Chauhan(CT60) (1).docx'\n",
            "'Urmi Chauhan(CT60) (1).gdoc'\n",
            "'Urmi Chauhan(CT60).docx'\n",
            "'Urmi Chauhan(CT60).gdoc'\n",
            "'voice flow F.gdoc'\n",
            "'voice flow F.txt'\n",
            "'WhatsApp Image 2021-07-24 at 1.41.43 PM.jpeg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "32nNonRSSaQq",
        "outputId": "064bb129-b5f2-4cbd-abb2-9b6ab9def3af"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cfd7a7f-7573-4619-bd68-80db54d92836\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cfd7a7f-7573-4619-bd68-80db54d92836')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cfd7a7f-7573-4619-bd68-80db54d92836 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cfd7a7f-7573-4619-bd68-80db54d92836');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "bfffbf5a-d0c4-486d-91b0-1a539a76d1d2"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "c603f6f2-4303-4e10-b3f1-0e266aa13312"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "adf10cdc-6e51-42ab-edd2-0e8a39ce808f"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "8918d66f-ed9c-4060-c432-146ab4ce9ec9"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "c3e9c575-cc25-40ce-d5b7-c96df71d4bd8"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "74ecda9f-ffd5-41cb-8b0c-334a52618cba"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288fd21a-d3ee-4e47-964b-8fe300b5a29c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(5, activation='tanh'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147\n",
            "Trainable params: 147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "e7680cfd-5328-4292-bf7b-b4aa570a49e0"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=750, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6535 - accuracy: 0.6741 - val_loss: 0.6581 - val_accuracy: 0.6260\n",
            "Epoch 2/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6680 - val_loss: 0.6594 - val_accuracy: 0.6260\n",
            "Epoch 3/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6680 - val_loss: 0.6478 - val_accuracy: 0.6260\n",
            "Epoch 4/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6680 - val_loss: 0.6388 - val_accuracy: 0.6260\n",
            "Epoch 5/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6680 - val_loss: 0.6323 - val_accuracy: 0.6260\n",
            "Epoch 6/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.6680 - val_loss: 0.6197 - val_accuracy: 0.6341\n",
            "Epoch 7/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6741 - val_loss: 0.6078 - val_accuracy: 0.6423\n",
            "Epoch 8/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.5958 - accuracy: 0.6782 - val_loss: 0.5932 - val_accuracy: 0.6829\n",
            "Epoch 9/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.6945 - val_loss: 0.5850 - val_accuracy: 0.6911\n",
            "Epoch 10/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5778 - accuracy: 0.7088 - val_loss: 0.5722 - val_accuracy: 0.7317\n",
            "Epoch 11/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5703 - accuracy: 0.7149 - val_loss: 0.5688 - val_accuracy: 0.7073\n",
            "Epoch 12/750\n",
            "123/123 [==============================] - 1s 8ms/step - loss: 0.5625 - accuracy: 0.7169 - val_loss: 0.5588 - val_accuracy: 0.7317\n",
            "Epoch 13/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.7128 - val_loss: 0.5486 - val_accuracy: 0.7236\n",
            "Epoch 14/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.7149 - val_loss: 0.5473 - val_accuracy: 0.7154\n",
            "Epoch 15/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.5478 - accuracy: 0.7189 - val_loss: 0.5509 - val_accuracy: 0.7154\n",
            "Epoch 16/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7169 - val_loss: 0.5475 - val_accuracy: 0.7154\n",
            "Epoch 17/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7108 - val_loss: 0.5352 - val_accuracy: 0.7317\n",
            "Epoch 18/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.5367 - accuracy: 0.7332 - val_loss: 0.5262 - val_accuracy: 0.7480\n",
            "Epoch 19/750\n",
            "123/123 [==============================] - 1s 7ms/step - loss: 0.5325 - accuracy: 0.7189 - val_loss: 0.5207 - val_accuracy: 0.7642\n",
            "Epoch 20/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7352 - val_loss: 0.5460 - val_accuracy: 0.7073\n",
            "Epoch 21/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7251 - val_loss: 0.5138 - val_accuracy: 0.7642\n",
            "Epoch 22/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7332 - val_loss: 0.5251 - val_accuracy: 0.7317\n",
            "Epoch 23/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7475 - val_loss: 0.5117 - val_accuracy: 0.7561\n",
            "Epoch 24/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7312 - val_loss: 0.5042 - val_accuracy: 0.7642\n",
            "Epoch 25/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7434 - val_loss: 0.5127 - val_accuracy: 0.7480\n",
            "Epoch 26/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7373 - val_loss: 0.5030 - val_accuracy: 0.7724\n",
            "Epoch 27/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7454 - val_loss: 0.5060 - val_accuracy: 0.7805\n",
            "Epoch 28/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7352 - val_loss: 0.5002 - val_accuracy: 0.7805\n",
            "Epoch 29/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7536 - val_loss: 0.4936 - val_accuracy: 0.7724\n",
            "Epoch 30/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7515 - val_loss: 0.5022 - val_accuracy: 0.7805\n",
            "Epoch 31/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7536 - val_loss: 0.4910 - val_accuracy: 0.7805\n",
            "Epoch 32/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7475 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 33/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7597 - val_loss: 0.4936 - val_accuracy: 0.7724\n",
            "Epoch 34/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7515 - val_loss: 0.5015 - val_accuracy: 0.7805\n",
            "Epoch 35/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7536 - val_loss: 0.4971 - val_accuracy: 0.7724\n",
            "Epoch 36/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7556 - val_loss: 0.4857 - val_accuracy: 0.7805\n",
            "Epoch 37/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7536 - val_loss: 0.4995 - val_accuracy: 0.7805\n",
            "Epoch 38/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7637 - val_loss: 0.4890 - val_accuracy: 0.7805\n",
            "Epoch 39/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7637 - val_loss: 0.5660 - val_accuracy: 0.7398\n",
            "Epoch 40/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7536 - val_loss: 0.5057 - val_accuracy: 0.7886\n",
            "Epoch 41/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7475 - val_loss: 0.4966 - val_accuracy: 0.7886\n",
            "Epoch 42/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7536 - val_loss: 0.4827 - val_accuracy: 0.7724\n",
            "Epoch 43/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7515 - val_loss: 0.4812 - val_accuracy: 0.7724\n",
            "Epoch 44/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7495 - val_loss: 0.4838 - val_accuracy: 0.7805\n",
            "Epoch 45/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7454 - val_loss: 0.4785 - val_accuracy: 0.7805\n",
            "Epoch 46/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7597 - val_loss: 0.5239 - val_accuracy: 0.7480\n",
            "Epoch 47/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7515 - val_loss: 0.4933 - val_accuracy: 0.7724\n",
            "Epoch 48/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7556 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 49/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7475 - val_loss: 0.4771 - val_accuracy: 0.7724\n",
            "Epoch 50/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7576 - val_loss: 0.4789 - val_accuracy: 0.7886\n",
            "Epoch 51/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7678 - val_loss: 0.4805 - val_accuracy: 0.7805\n",
            "Epoch 52/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7597 - val_loss: 0.4826 - val_accuracy: 0.7642\n",
            "Epoch 53/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7617 - val_loss: 0.4800 - val_accuracy: 0.7561\n",
            "Epoch 54/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7597 - val_loss: 0.4758 - val_accuracy: 0.7805\n",
            "Epoch 55/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7495 - val_loss: 0.4760 - val_accuracy: 0.7805\n",
            "Epoch 56/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7576 - val_loss: 0.4782 - val_accuracy: 0.7561\n",
            "Epoch 57/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7597 - val_loss: 0.4922 - val_accuracy: 0.7886\n",
            "Epoch 58/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7536 - val_loss: 0.4822 - val_accuracy: 0.7642\n",
            "Epoch 59/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7617 - val_loss: 0.4815 - val_accuracy: 0.7967\n",
            "Epoch 60/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7576 - val_loss: 0.4738 - val_accuracy: 0.7642\n",
            "Epoch 61/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7515 - val_loss: 0.4771 - val_accuracy: 0.7561\n",
            "Epoch 62/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7637 - val_loss: 0.5162 - val_accuracy: 0.7642\n",
            "Epoch 63/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7658 - val_loss: 0.4774 - val_accuracy: 0.7886\n",
            "Epoch 64/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7658 - val_loss: 0.4825 - val_accuracy: 0.7967\n",
            "Epoch 65/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7617 - val_loss: 0.4747 - val_accuracy: 0.7886\n",
            "Epoch 66/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7617 - val_loss: 0.4735 - val_accuracy: 0.7724\n",
            "Epoch 67/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7515 - val_loss: 0.4724 - val_accuracy: 0.7642\n",
            "Epoch 68/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7556 - val_loss: 0.4780 - val_accuracy: 0.7967\n",
            "Epoch 69/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7637 - val_loss: 0.4724 - val_accuracy: 0.7561\n",
            "Epoch 70/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7658 - val_loss: 0.4721 - val_accuracy: 0.7805\n",
            "Epoch 71/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7617 - val_loss: 0.4726 - val_accuracy: 0.7886\n",
            "Epoch 72/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7617 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
            "Epoch 73/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7658 - val_loss: 0.4710 - val_accuracy: 0.7561\n",
            "Epoch 74/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7536 - val_loss: 0.4840 - val_accuracy: 0.7886\n",
            "Epoch 75/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7617 - val_loss: 0.4736 - val_accuracy: 0.7886\n",
            "Epoch 76/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7637 - val_loss: 0.4802 - val_accuracy: 0.7561\n",
            "Epoch 77/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7576 - val_loss: 0.4850 - val_accuracy: 0.7886\n",
            "Epoch 78/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7637 - val_loss: 0.4697 - val_accuracy: 0.7886\n",
            "Epoch 79/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7678 - val_loss: 0.4762 - val_accuracy: 0.7967\n",
            "Epoch 80/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7678 - val_loss: 0.4884 - val_accuracy: 0.7886\n",
            "Epoch 81/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7658 - val_loss: 0.4703 - val_accuracy: 0.7886\n",
            "Epoch 82/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7637 - val_loss: 0.4709 - val_accuracy: 0.7967\n",
            "Epoch 83/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7637 - val_loss: 0.4739 - val_accuracy: 0.7642\n",
            "Epoch 84/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7678 - val_loss: 0.4687 - val_accuracy: 0.7642\n",
            "Epoch 85/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7658 - val_loss: 0.4762 - val_accuracy: 0.7561\n",
            "Epoch 86/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7841 - val_loss: 0.5199 - val_accuracy: 0.7561\n",
            "Epoch 87/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7576 - val_loss: 0.4686 - val_accuracy: 0.7886\n",
            "Epoch 88/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7637 - val_loss: 0.4842 - val_accuracy: 0.7886\n",
            "Epoch 89/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7536 - val_loss: 0.4674 - val_accuracy: 0.7805\n",
            "Epoch 90/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7556 - val_loss: 0.5084 - val_accuracy: 0.8049\n",
            "Epoch 91/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7576 - val_loss: 0.4727 - val_accuracy: 0.7886\n",
            "Epoch 92/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7617 - val_loss: 0.4698 - val_accuracy: 0.7967\n",
            "Epoch 93/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7739 - val_loss: 0.4782 - val_accuracy: 0.7967\n",
            "Epoch 94/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7719 - val_loss: 0.4709 - val_accuracy: 0.7886\n",
            "Epoch 95/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7597 - val_loss: 0.4723 - val_accuracy: 0.7886\n",
            "Epoch 96/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7678 - val_loss: 0.4803 - val_accuracy: 0.7561\n",
            "Epoch 97/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7678 - val_loss: 0.4726 - val_accuracy: 0.7642\n",
            "Epoch 98/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7658 - val_loss: 0.4704 - val_accuracy: 0.7886\n",
            "Epoch 99/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7515 - val_loss: 0.4687 - val_accuracy: 0.7805\n",
            "Epoch 100/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7617 - val_loss: 0.4705 - val_accuracy: 0.7886\n",
            "Epoch 101/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7617 - val_loss: 0.4699 - val_accuracy: 0.7724\n",
            "Epoch 102/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7597 - val_loss: 0.4676 - val_accuracy: 0.7805\n",
            "Epoch 103/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7719 - val_loss: 0.4996 - val_accuracy: 0.8049\n",
            "Epoch 104/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7658 - val_loss: 0.4713 - val_accuracy: 0.7886\n",
            "Epoch 105/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7699 - val_loss: 0.4672 - val_accuracy: 0.7886\n",
            "Epoch 106/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7699 - val_loss: 0.4713 - val_accuracy: 0.7886\n",
            "Epoch 107/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7617 - val_loss: 0.4850 - val_accuracy: 0.7886\n",
            "Epoch 108/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7699 - val_loss: 0.4694 - val_accuracy: 0.7886\n",
            "Epoch 109/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7800 - val_loss: 0.4722 - val_accuracy: 0.7561\n",
            "Epoch 110/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7699 - val_loss: 0.4685 - val_accuracy: 0.7642\n",
            "Epoch 111/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7678 - val_loss: 0.4689 - val_accuracy: 0.7886\n",
            "Epoch 112/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7637 - val_loss: 0.4689 - val_accuracy: 0.7642\n",
            "Epoch 113/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7719 - val_loss: 0.4688 - val_accuracy: 0.7886\n",
            "Epoch 114/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7556 - val_loss: 0.4677 - val_accuracy: 0.7642\n",
            "Epoch 115/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7617 - val_loss: 0.4768 - val_accuracy: 0.7561\n",
            "Epoch 116/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7597 - val_loss: 0.4761 - val_accuracy: 0.7886\n",
            "Epoch 117/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7597 - val_loss: 0.4699 - val_accuracy: 0.7886\n",
            "Epoch 118/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7536 - val_loss: 0.4721 - val_accuracy: 0.7886\n",
            "Epoch 119/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7576 - val_loss: 0.4679 - val_accuracy: 0.7886\n",
            "Epoch 120/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7658 - val_loss: 0.4699 - val_accuracy: 0.7886\n",
            "Epoch 121/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7719 - val_loss: 0.4667 - val_accuracy: 0.7886\n",
            "Epoch 122/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7556 - val_loss: 0.4748 - val_accuracy: 0.7886\n",
            "Epoch 123/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7800 - val_loss: 0.4671 - val_accuracy: 0.7724\n",
            "Epoch 124/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.4651 - val_accuracy: 0.7724\n",
            "Epoch 125/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7556 - val_loss: 0.4658 - val_accuracy: 0.7967\n",
            "Epoch 126/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7556 - val_loss: 0.4890 - val_accuracy: 0.7967\n",
            "Epoch 127/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7637 - val_loss: 0.4660 - val_accuracy: 0.7805\n",
            "Epoch 128/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7719 - val_loss: 0.4700 - val_accuracy: 0.7886\n",
            "Epoch 129/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7678 - val_loss: 0.4655 - val_accuracy: 0.7886\n",
            "Epoch 130/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7597 - val_loss: 0.4665 - val_accuracy: 0.7805\n",
            "Epoch 131/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7967\n",
            "Epoch 132/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7739 - val_loss: 0.4648 - val_accuracy: 0.7805\n",
            "Epoch 133/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7637 - val_loss: 0.5048 - val_accuracy: 0.7561\n",
            "Epoch 134/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7678 - val_loss: 0.4686 - val_accuracy: 0.7642\n",
            "Epoch 135/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7597 - val_loss: 0.4697 - val_accuracy: 0.7886\n",
            "Epoch 136/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7495 - val_loss: 0.4770 - val_accuracy: 0.7642\n",
            "Epoch 137/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7658 - val_loss: 0.4678 - val_accuracy: 0.7561\n",
            "Epoch 138/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.4666 - val_accuracy: 0.7724\n",
            "Epoch 139/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7556 - val_loss: 0.4754 - val_accuracy: 0.7805\n",
            "Epoch 140/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7678 - val_loss: 0.4732 - val_accuracy: 0.7561\n",
            "Epoch 141/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7699 - val_loss: 0.4657 - val_accuracy: 0.7805\n",
            "Epoch 142/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7637 - val_loss: 0.4682 - val_accuracy: 0.7561\n",
            "Epoch 143/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7597 - val_loss: 0.4680 - val_accuracy: 0.7561\n",
            "Epoch 144/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7576 - val_loss: 0.4683 - val_accuracy: 0.7886\n",
            "Epoch 145/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7719 - val_loss: 0.4940 - val_accuracy: 0.7967\n",
            "Epoch 146/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7515 - val_loss: 0.4681 - val_accuracy: 0.7886\n",
            "Epoch 147/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7678 - val_loss: 0.4715 - val_accuracy: 0.7886\n",
            "Epoch 148/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7637 - val_loss: 0.5024 - val_accuracy: 0.7967\n",
            "Epoch 149/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7678 - val_loss: 0.4810 - val_accuracy: 0.7724\n",
            "Epoch 150/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7597 - val_loss: 0.4687 - val_accuracy: 0.7561\n",
            "Epoch 151/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7617 - val_loss: 0.4660 - val_accuracy: 0.7886\n",
            "Epoch 152/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7719 - val_loss: 0.4688 - val_accuracy: 0.7805\n",
            "Epoch 153/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7719 - val_loss: 0.4765 - val_accuracy: 0.7805\n",
            "Epoch 154/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.5326 - val_accuracy: 0.7886\n",
            "Epoch 155/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.4702 - val_accuracy: 0.7561\n",
            "Epoch 156/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7454 - val_loss: 0.4672 - val_accuracy: 0.7886\n",
            "Epoch 157/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7658 - val_loss: 0.4697 - val_accuracy: 0.7561\n",
            "Epoch 158/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7597 - val_loss: 0.4666 - val_accuracy: 0.7886\n",
            "Epoch 159/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7658 - val_loss: 0.4680 - val_accuracy: 0.7561\n",
            "Epoch 160/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7637 - val_loss: 0.4740 - val_accuracy: 0.7561\n",
            "Epoch 161/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7658 - val_loss: 0.4746 - val_accuracy: 0.7886\n",
            "Epoch 162/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7617 - val_loss: 0.4754 - val_accuracy: 0.7805\n",
            "Epoch 163/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4655 - val_accuracy: 0.7886\n",
            "Epoch 164/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7699 - val_loss: 0.4693 - val_accuracy: 0.7642\n",
            "Epoch 165/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7658 - val_loss: 0.4666 - val_accuracy: 0.7886\n",
            "Epoch 166/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7658 - val_loss: 0.4872 - val_accuracy: 0.7724\n",
            "Epoch 167/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7637 - val_loss: 0.4664 - val_accuracy: 0.7724\n",
            "Epoch 168/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7800 - val_loss: 0.4756 - val_accuracy: 0.7886\n",
            "Epoch 169/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7800 - val_loss: 0.4728 - val_accuracy: 0.7886\n",
            "Epoch 170/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7658 - val_loss: 0.4883 - val_accuracy: 0.7967\n",
            "Epoch 171/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7699 - val_loss: 0.4715 - val_accuracy: 0.7805\n",
            "Epoch 172/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7780 - val_loss: 0.4664 - val_accuracy: 0.7724\n",
            "Epoch 173/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7576 - val_loss: 0.4997 - val_accuracy: 0.7886\n",
            "Epoch 174/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7719 - val_loss: 0.4828 - val_accuracy: 0.7724\n",
            "Epoch 175/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7780 - val_loss: 0.4726 - val_accuracy: 0.7886\n",
            "Epoch 176/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7800 - val_loss: 0.4843 - val_accuracy: 0.7642\n",
            "Epoch 177/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7597 - val_loss: 0.4665 - val_accuracy: 0.7886\n",
            "Epoch 178/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7413 - val_loss: 0.4645 - val_accuracy: 0.7886\n",
            "Epoch 179/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4656 - val_accuracy: 0.7724\n",
            "Epoch 180/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7719 - val_loss: 0.4908 - val_accuracy: 0.7724\n",
            "Epoch 181/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7699 - val_loss: 0.4645 - val_accuracy: 0.7886\n",
            "Epoch 182/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.4771 - val_accuracy: 0.7805\n",
            "Epoch 183/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.4679 - val_accuracy: 0.7805\n",
            "Epoch 184/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7658 - val_loss: 0.4637 - val_accuracy: 0.7967\n",
            "Epoch 185/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7637 - val_loss: 0.4642 - val_accuracy: 0.8049\n",
            "Epoch 186/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7678 - val_loss: 0.4675 - val_accuracy: 0.7805\n",
            "Epoch 187/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7556 - val_loss: 0.4646 - val_accuracy: 0.7967\n",
            "Epoch 188/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7658 - val_loss: 0.4681 - val_accuracy: 0.7642\n",
            "Epoch 189/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7658 - val_loss: 0.4901 - val_accuracy: 0.7967\n",
            "Epoch 190/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7658 - val_loss: 0.4638 - val_accuracy: 0.7886\n",
            "Epoch 191/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7800 - val_loss: 0.4845 - val_accuracy: 0.7967\n",
            "Epoch 192/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7780 - val_loss: 0.4885 - val_accuracy: 0.7967\n",
            "Epoch 193/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7739 - val_loss: 0.4634 - val_accuracy: 0.7967\n",
            "Epoch 194/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7617 - val_loss: 0.4637 - val_accuracy: 0.7886\n",
            "Epoch 195/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7760 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
            "Epoch 196/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7800 - val_loss: 0.4698 - val_accuracy: 0.7642\n",
            "Epoch 197/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7719 - val_loss: 0.4741 - val_accuracy: 0.7561\n",
            "Epoch 198/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7821 - val_loss: 0.4656 - val_accuracy: 0.7886\n",
            "Epoch 199/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7780 - val_loss: 0.4741 - val_accuracy: 0.7805\n",
            "Epoch 200/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7800 - val_loss: 0.4665 - val_accuracy: 0.7805\n",
            "Epoch 201/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7719 - val_loss: 0.4675 - val_accuracy: 0.7805\n",
            "Epoch 202/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7678 - val_loss: 0.5076 - val_accuracy: 0.8049\n",
            "Epoch 203/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.4635 - val_accuracy: 0.7886\n",
            "Epoch 204/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.4644 - val_accuracy: 0.7886\n",
            "Epoch 205/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7678 - val_loss: 0.4735 - val_accuracy: 0.7805\n",
            "Epoch 206/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7800 - val_loss: 0.4721 - val_accuracy: 0.7805\n",
            "Epoch 207/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7862 - val_loss: 0.4651 - val_accuracy: 0.7886\n",
            "Epoch 208/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7699 - val_loss: 0.4637 - val_accuracy: 0.7886\n",
            "Epoch 209/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7862 - val_loss: 0.4634 - val_accuracy: 0.7967\n",
            "Epoch 210/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7637 - val_loss: 0.4709 - val_accuracy: 0.7805\n",
            "Epoch 211/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7678 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
            "Epoch 212/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7739 - val_loss: 0.4664 - val_accuracy: 0.7805\n",
            "Epoch 213/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7678 - val_loss: 0.4712 - val_accuracy: 0.7805\n",
            "Epoch 214/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7882 - val_loss: 0.4777 - val_accuracy: 0.7642\n",
            "Epoch 215/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7658 - val_loss: 0.4715 - val_accuracy: 0.7642\n",
            "Epoch 216/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7739 - val_loss: 0.4643 - val_accuracy: 0.7886\n",
            "Epoch 217/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.4766 - val_accuracy: 0.7805\n",
            "Epoch 218/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7719 - val_loss: 0.4639 - val_accuracy: 0.7967\n",
            "Epoch 219/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7658 - val_loss: 0.4665 - val_accuracy: 0.7886\n",
            "Epoch 220/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7719 - val_loss: 0.4727 - val_accuracy: 0.7642\n",
            "Epoch 221/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7637 - val_loss: 0.4703 - val_accuracy: 0.7805\n",
            "Epoch 222/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7597 - val_loss: 0.4644 - val_accuracy: 0.7886\n",
            "Epoch 223/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7739 - val_loss: 0.4635 - val_accuracy: 0.7967\n",
            "Epoch 224/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4659 - val_accuracy: 0.7886\n",
            "Epoch 225/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7637 - val_loss: 0.4648 - val_accuracy: 0.7886\n",
            "Epoch 226/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7658 - val_loss: 0.4789 - val_accuracy: 0.7805\n",
            "Epoch 227/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.5250 - val_accuracy: 0.7317\n",
            "Epoch 228/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.4654 - val_accuracy: 0.7805\n",
            "Epoch 229/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4633 - val_accuracy: 0.7886\n",
            "Epoch 230/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7719 - val_loss: 0.4722 - val_accuracy: 0.7805\n",
            "Epoch 231/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4660 - val_accuracy: 0.7886\n",
            "Epoch 232/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7821 - val_loss: 0.4783 - val_accuracy: 0.7805\n",
            "Epoch 233/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7678 - val_loss: 0.4683 - val_accuracy: 0.7805\n",
            "Epoch 234/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7821 - val_loss: 0.5025 - val_accuracy: 0.7561\n",
            "Epoch 235/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7699 - val_loss: 0.5110 - val_accuracy: 0.7967\n",
            "Epoch 236/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7719 - val_loss: 0.4864 - val_accuracy: 0.7967\n",
            "Epoch 237/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7862 - val_loss: 0.4755 - val_accuracy: 0.7805\n",
            "Epoch 238/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7780 - val_loss: 0.4635 - val_accuracy: 0.7805\n",
            "Epoch 239/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7862 - val_loss: 0.4628 - val_accuracy: 0.7886\n",
            "Epoch 240/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7637 - val_loss: 0.4855 - val_accuracy: 0.7805\n",
            "Epoch 241/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7719 - val_loss: 0.4627 - val_accuracy: 0.7967\n",
            "Epoch 242/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7637 - val_loss: 0.4747 - val_accuracy: 0.7886\n",
            "Epoch 243/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7862 - val_loss: 0.4638 - val_accuracy: 0.7805\n",
            "Epoch 244/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7617 - val_loss: 0.4651 - val_accuracy: 0.7805\n",
            "Epoch 245/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7678 - val_loss: 0.4639 - val_accuracy: 0.7967\n",
            "Epoch 246/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7739 - val_loss: 0.4734 - val_accuracy: 0.7724\n",
            "Epoch 247/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7821 - val_loss: 0.4790 - val_accuracy: 0.7886\n",
            "Epoch 248/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7902 - val_loss: 0.4719 - val_accuracy: 0.7805\n",
            "Epoch 249/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7821 - val_loss: 0.4667 - val_accuracy: 0.7886\n",
            "Epoch 250/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7780 - val_loss: 0.5026 - val_accuracy: 0.7967\n",
            "Epoch 251/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7841 - val_loss: 0.4751 - val_accuracy: 0.7805\n",
            "Epoch 252/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7800 - val_loss: 0.4636 - val_accuracy: 0.7805\n",
            "Epoch 253/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7678 - val_loss: 0.4688 - val_accuracy: 0.7724\n",
            "Epoch 254/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7821 - val_loss: 0.4706 - val_accuracy: 0.7724\n",
            "Epoch 255/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7739 - val_loss: 0.4802 - val_accuracy: 0.7805\n",
            "Epoch 256/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7739 - val_loss: 0.4821 - val_accuracy: 0.7967\n",
            "Epoch 257/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7780 - val_loss: 0.4705 - val_accuracy: 0.7724\n",
            "Epoch 258/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7637 - val_loss: 0.4629 - val_accuracy: 0.7967\n",
            "Epoch 259/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7739 - val_loss: 0.4656 - val_accuracy: 0.7886\n",
            "Epoch 260/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7719 - val_loss: 0.4683 - val_accuracy: 0.7805\n",
            "Epoch 261/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7719 - val_loss: 0.4633 - val_accuracy: 0.7886\n",
            "Epoch 262/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7923 - val_loss: 0.4632 - val_accuracy: 0.7967\n",
            "Epoch 263/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7678 - val_loss: 0.4731 - val_accuracy: 0.7805\n",
            "Epoch 264/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7719 - val_loss: 0.4631 - val_accuracy: 0.7967\n",
            "Epoch 265/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4631 - val_accuracy: 0.7886\n",
            "Epoch 266/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7719 - val_loss: 0.4622 - val_accuracy: 0.7967\n",
            "Epoch 267/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7780 - val_loss: 0.4639 - val_accuracy: 0.7886\n",
            "Epoch 268/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7943 - val_loss: 0.4641 - val_accuracy: 0.7886\n",
            "Epoch 269/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7821 - val_loss: 0.4802 - val_accuracy: 0.7805\n",
            "Epoch 270/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7862 - val_loss: 0.4694 - val_accuracy: 0.7805\n",
            "Epoch 271/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7637 - val_loss: 0.4682 - val_accuracy: 0.7805\n",
            "Epoch 272/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.4657 - val_accuracy: 0.7805\n",
            "Epoch 273/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7658 - val_loss: 0.4614 - val_accuracy: 0.7967\n",
            "Epoch 274/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4690 - val_accuracy: 0.7805\n",
            "Epoch 275/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7862 - val_loss: 0.4628 - val_accuracy: 0.7967\n",
            "Epoch 276/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7658 - val_loss: 0.4619 - val_accuracy: 0.7967\n",
            "Epoch 277/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7943 - val_loss: 0.4925 - val_accuracy: 0.7642\n",
            "Epoch 278/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.4731 - val_accuracy: 0.7724\n",
            "Epoch 279/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7780 - val_loss: 0.4638 - val_accuracy: 0.7886\n",
            "Epoch 280/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7739 - val_loss: 0.4950 - val_accuracy: 0.7561\n",
            "Epoch 281/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7678 - val_loss: 0.4644 - val_accuracy: 0.7886\n",
            "Epoch 282/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7739 - val_loss: 0.4763 - val_accuracy: 0.7805\n",
            "Epoch 283/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7821 - val_loss: 0.4621 - val_accuracy: 0.7886\n",
            "Epoch 284/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7739 - val_loss: 0.4659 - val_accuracy: 0.7886\n",
            "Epoch 285/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7821 - val_loss: 0.4720 - val_accuracy: 0.7805\n",
            "Epoch 286/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7739 - val_loss: 0.4633 - val_accuracy: 0.7886\n",
            "Epoch 287/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7780 - val_loss: 0.4632 - val_accuracy: 0.7886\n",
            "Epoch 288/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.4683 - val_accuracy: 0.7805\n",
            "Epoch 289/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7841 - val_loss: 0.4689 - val_accuracy: 0.7805\n",
            "Epoch 290/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7719 - val_loss: 0.4814 - val_accuracy: 0.7886\n",
            "Epoch 291/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7719 - val_loss: 0.4637 - val_accuracy: 0.7967\n",
            "Epoch 292/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7719 - val_loss: 0.5073 - val_accuracy: 0.7967\n",
            "Epoch 293/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7886\n",
            "Epoch 294/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7780 - val_loss: 0.4725 - val_accuracy: 0.7886\n",
            "Epoch 295/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7556 - val_loss: 0.4682 - val_accuracy: 0.7805\n",
            "Epoch 296/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7800 - val_loss: 0.4670 - val_accuracy: 0.7886\n",
            "Epoch 297/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7658 - val_loss: 0.4827 - val_accuracy: 0.7967\n",
            "Epoch 298/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7780 - val_loss: 0.4866 - val_accuracy: 0.7967\n",
            "Epoch 299/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7841 - val_loss: 0.4676 - val_accuracy: 0.7886\n",
            "Epoch 300/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7617 - val_loss: 0.4880 - val_accuracy: 0.7967\n",
            "Epoch 301/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7719 - val_loss: 0.4797 - val_accuracy: 0.7805\n",
            "Epoch 302/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.4734 - val_accuracy: 0.7724\n",
            "Epoch 303/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7719 - val_loss: 0.4729 - val_accuracy: 0.7724\n",
            "Epoch 304/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7739 - val_loss: 0.4999 - val_accuracy: 0.7967\n",
            "Epoch 305/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.4705 - val_accuracy: 0.7642\n",
            "Epoch 306/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7780 - val_loss: 0.4715 - val_accuracy: 0.7642\n",
            "Epoch 307/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.4797 - val_accuracy: 0.7805\n",
            "Epoch 308/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7841 - val_loss: 0.4643 - val_accuracy: 0.7886\n",
            "Epoch 309/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7800 - val_loss: 0.4680 - val_accuracy: 0.7724\n",
            "Epoch 310/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7923 - val_loss: 0.4680 - val_accuracy: 0.7724\n",
            "Epoch 311/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7617 - val_loss: 0.4667 - val_accuracy: 0.7805\n",
            "Epoch 312/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7841 - val_loss: 0.4929 - val_accuracy: 0.7967\n",
            "Epoch 313/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.4654 - val_accuracy: 0.7805\n",
            "Epoch 314/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7902 - val_loss: 0.4698 - val_accuracy: 0.7805\n",
            "Epoch 315/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7780 - val_loss: 0.4665 - val_accuracy: 0.7805\n",
            "Epoch 316/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7923 - val_loss: 0.4654 - val_accuracy: 0.7805\n",
            "Epoch 317/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7699 - val_loss: 0.4672 - val_accuracy: 0.7642\n",
            "Epoch 318/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7862 - val_loss: 0.4886 - val_accuracy: 0.7967\n",
            "Epoch 319/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7882 - val_loss: 0.4732 - val_accuracy: 0.7642\n",
            "Epoch 320/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7800 - val_loss: 0.4763 - val_accuracy: 0.7724\n",
            "Epoch 321/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7800 - val_loss: 0.4652 - val_accuracy: 0.7886\n",
            "Epoch 322/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7902 - val_loss: 0.4646 - val_accuracy: 0.7886\n",
            "Epoch 323/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7800 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 324/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7724\n",
            "Epoch 325/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7719 - val_loss: 0.4693 - val_accuracy: 0.7724\n",
            "Epoch 326/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4749 - val_accuracy: 0.7805\n",
            "Epoch 327/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7862 - val_loss: 0.4659 - val_accuracy: 0.7805\n",
            "Epoch 328/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5004 - val_accuracy: 0.7967\n",
            "Epoch 329/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7862 - val_loss: 0.4653 - val_accuracy: 0.7805\n",
            "Epoch 330/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7658 - val_loss: 0.4662 - val_accuracy: 0.7724\n",
            "Epoch 331/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7780 - val_loss: 0.4673 - val_accuracy: 0.7805\n",
            "Epoch 332/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7821 - val_loss: 0.4703 - val_accuracy: 0.7642\n",
            "Epoch 333/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7902 - val_loss: 0.5251 - val_accuracy: 0.7967\n",
            "Epoch 334/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7800 - val_loss: 0.4714 - val_accuracy: 0.7724\n",
            "Epoch 335/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7841 - val_loss: 0.4817 - val_accuracy: 0.7724\n",
            "Epoch 336/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7800 - val_loss: 0.4695 - val_accuracy: 0.7561\n",
            "Epoch 337/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7963 - val_loss: 0.4639 - val_accuracy: 0.7886\n",
            "Epoch 338/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7576 - val_loss: 0.4742 - val_accuracy: 0.7724\n",
            "Epoch 339/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7841 - val_loss: 0.4697 - val_accuracy: 0.7724\n",
            "Epoch 340/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7780 - val_loss: 0.5093 - val_accuracy: 0.7967\n",
            "Epoch 341/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7739 - val_loss: 0.4820 - val_accuracy: 0.8049\n",
            "Epoch 342/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.4661 - val_accuracy: 0.7805\n",
            "Epoch 343/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7821 - val_loss: 0.4646 - val_accuracy: 0.7805\n",
            "Epoch 344/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7719 - val_loss: 0.4669 - val_accuracy: 0.7805\n",
            "Epoch 345/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7862 - val_loss: 0.4694 - val_accuracy: 0.7805\n",
            "Epoch 346/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7760 - val_loss: 0.4677 - val_accuracy: 0.7724\n",
            "Epoch 347/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.4670 - val_accuracy: 0.7724\n",
            "Epoch 348/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7678 - val_loss: 0.4776 - val_accuracy: 0.7724\n",
            "Epoch 349/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.4677 - val_accuracy: 0.7724\n",
            "Epoch 350/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7943 - val_loss: 0.4776 - val_accuracy: 0.7724\n",
            "Epoch 351/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7780 - val_loss: 0.4694 - val_accuracy: 0.7724\n",
            "Epoch 352/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7821 - val_loss: 0.4665 - val_accuracy: 0.7805\n",
            "Epoch 353/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7821 - val_loss: 0.4793 - val_accuracy: 0.7805\n",
            "Epoch 354/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7800 - val_loss: 0.4993 - val_accuracy: 0.7967\n",
            "Epoch 355/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7984 - val_loss: 0.5084 - val_accuracy: 0.7967\n",
            "Epoch 356/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7800 - val_loss: 0.4658 - val_accuracy: 0.7886\n",
            "Epoch 357/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7923 - val_loss: 0.4687 - val_accuracy: 0.7724\n",
            "Epoch 358/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7800 - val_loss: 0.4723 - val_accuracy: 0.7805\n",
            "Epoch 359/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7841 - val_loss: 0.4739 - val_accuracy: 0.7805\n",
            "Epoch 360/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7800 - val_loss: 0.4669 - val_accuracy: 0.7642\n",
            "Epoch 361/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7821 - val_loss: 0.4646 - val_accuracy: 0.7886\n",
            "Epoch 362/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7841 - val_loss: 0.4815 - val_accuracy: 0.7805\n",
            "Epoch 363/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7821 - val_loss: 0.4643 - val_accuracy: 0.7967\n",
            "Epoch 364/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4973 - val_accuracy: 0.7967\n",
            "Epoch 365/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7862 - val_loss: 0.4669 - val_accuracy: 0.7805\n",
            "Epoch 366/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7862 - val_loss: 0.4650 - val_accuracy: 0.7805\n",
            "Epoch 367/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.4684 - val_accuracy: 0.7642\n",
            "Epoch 368/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7841 - val_loss: 0.4667 - val_accuracy: 0.7724\n",
            "Epoch 369/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7739 - val_loss: 0.4655 - val_accuracy: 0.7724\n",
            "Epoch 370/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7821 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
            "Epoch 371/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7719 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 372/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7902 - val_loss: 0.4722 - val_accuracy: 0.7805\n",
            "Epoch 373/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7699 - val_loss: 0.4667 - val_accuracy: 0.7724\n",
            "Epoch 374/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4742 - val_accuracy: 0.7642\n",
            "Epoch 375/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4835 - val_accuracy: 0.7724\n",
            "Epoch 376/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7821 - val_loss: 0.4680 - val_accuracy: 0.7724\n",
            "Epoch 377/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7967\n",
            "Epoch 378/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7902 - val_loss: 0.4656 - val_accuracy: 0.7724\n",
            "Epoch 379/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7841 - val_loss: 0.5274 - val_accuracy: 0.7967\n",
            "Epoch 380/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.4690 - val_accuracy: 0.7561\n",
            "Epoch 381/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7739 - val_loss: 0.4764 - val_accuracy: 0.7724\n",
            "Epoch 382/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7862 - val_loss: 0.4743 - val_accuracy: 0.7724\n",
            "Epoch 383/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7719 - val_loss: 0.4858 - val_accuracy: 0.7886\n",
            "Epoch 384/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7923 - val_loss: 0.4677 - val_accuracy: 0.7724\n",
            "Epoch 385/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7902 - val_loss: 0.4687 - val_accuracy: 0.7561\n",
            "Epoch 386/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4780 - val_accuracy: 0.7724\n",
            "Epoch 387/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7699 - val_loss: 0.4810 - val_accuracy: 0.7967\n",
            "Epoch 388/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7821 - val_loss: 0.5027 - val_accuracy: 0.7967\n",
            "Epoch 389/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7800 - val_loss: 0.4816 - val_accuracy: 0.7724\n",
            "Epoch 390/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7800 - val_loss: 0.4771 - val_accuracy: 0.7561\n",
            "Epoch 391/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7821 - val_loss: 0.5016 - val_accuracy: 0.7886\n",
            "Epoch 392/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7821 - val_loss: 0.5212 - val_accuracy: 0.7967\n",
            "Epoch 393/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8004 - val_loss: 0.4810 - val_accuracy: 0.7642\n",
            "Epoch 394/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7780 - val_loss: 0.4688 - val_accuracy: 0.7724\n",
            "Epoch 395/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7805\n",
            "Epoch 396/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7821 - val_loss: 0.4975 - val_accuracy: 0.7967\n",
            "Epoch 397/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7719 - val_loss: 0.4755 - val_accuracy: 0.7561\n",
            "Epoch 398/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7821 - val_loss: 0.4689 - val_accuracy: 0.7642\n",
            "Epoch 399/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7841 - val_loss: 0.4858 - val_accuracy: 0.7724\n",
            "Epoch 400/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7821 - val_loss: 0.4851 - val_accuracy: 0.7724\n",
            "Epoch 401/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7821 - val_loss: 0.4698 - val_accuracy: 0.7642\n",
            "Epoch 402/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.4710 - val_accuracy: 0.7561\n",
            "Epoch 403/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7841 - val_loss: 0.4758 - val_accuracy: 0.7642\n",
            "Epoch 404/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7821 - val_loss: 0.4682 - val_accuracy: 0.7642\n",
            "Epoch 405/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7821 - val_loss: 0.4714 - val_accuracy: 0.7642\n",
            "Epoch 406/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7923 - val_loss: 0.4880 - val_accuracy: 0.7642\n",
            "Epoch 407/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.4819 - val_accuracy: 0.7967\n",
            "Epoch 408/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7800 - val_loss: 0.4684 - val_accuracy: 0.7724\n",
            "Epoch 409/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7943 - val_loss: 0.4856 - val_accuracy: 0.7642\n",
            "Epoch 410/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.4777 - val_accuracy: 0.7805\n",
            "Epoch 411/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7800 - val_loss: 0.4701 - val_accuracy: 0.7642\n",
            "Epoch 412/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7902 - val_loss: 0.4737 - val_accuracy: 0.7561\n",
            "Epoch 413/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7923 - val_loss: 0.4745 - val_accuracy: 0.7642\n",
            "Epoch 414/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7780 - val_loss: 0.4697 - val_accuracy: 0.7642\n",
            "Epoch 415/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7923 - val_loss: 0.4715 - val_accuracy: 0.7480\n",
            "Epoch 416/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7902 - val_loss: 0.5100 - val_accuracy: 0.7967\n",
            "Epoch 417/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7678 - val_loss: 0.4849 - val_accuracy: 0.7724\n",
            "Epoch 418/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7658 - val_loss: 0.4783 - val_accuracy: 0.7724\n",
            "Epoch 419/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7841 - val_loss: 0.5333 - val_accuracy: 0.7967\n",
            "Epoch 420/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7821 - val_loss: 0.4760 - val_accuracy: 0.7480\n",
            "Epoch 421/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7862 - val_loss: 0.4740 - val_accuracy: 0.7561\n",
            "Epoch 422/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7821 - val_loss: 0.4692 - val_accuracy: 0.7642\n",
            "Epoch 423/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7678 - val_loss: 0.4977 - val_accuracy: 0.7967\n",
            "Epoch 424/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.4703 - val_accuracy: 0.7561\n",
            "Epoch 425/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7780 - val_loss: 0.4705 - val_accuracy: 0.7642\n",
            "Epoch 426/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7967\n",
            "Epoch 427/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7800 - val_loss: 0.4821 - val_accuracy: 0.7642\n",
            "Epoch 428/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7902 - val_loss: 0.4715 - val_accuracy: 0.7480\n",
            "Epoch 429/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7943 - val_loss: 0.4692 - val_accuracy: 0.7561\n",
            "Epoch 430/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7821 - val_loss: 0.4882 - val_accuracy: 0.7724\n",
            "Epoch 431/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7719 - val_loss: 0.4853 - val_accuracy: 0.7642\n",
            "Epoch 432/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.4779 - val_accuracy: 0.7724\n",
            "Epoch 433/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7739 - val_loss: 0.4754 - val_accuracy: 0.7724\n",
            "Epoch 434/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7862 - val_loss: 0.4712 - val_accuracy: 0.7642\n",
            "Epoch 435/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7780 - val_loss: 0.5121 - val_accuracy: 0.7886\n",
            "Epoch 436/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7862 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
            "Epoch 437/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.4968 - val_accuracy: 0.7724\n",
            "Epoch 438/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7800 - val_loss: 0.4705 - val_accuracy: 0.7886\n",
            "Epoch 439/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7719 - val_loss: 0.4845 - val_accuracy: 0.7724\n",
            "Epoch 440/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7923 - val_loss: 0.4798 - val_accuracy: 0.7642\n",
            "Epoch 441/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7886\n",
            "Epoch 442/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7923 - val_loss: 0.4703 - val_accuracy: 0.7561\n",
            "Epoch 443/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7699 - val_loss: 0.4731 - val_accuracy: 0.7561\n",
            "Epoch 444/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7984 - val_loss: 0.4770 - val_accuracy: 0.7724\n",
            "Epoch 445/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7862 - val_loss: 0.4773 - val_accuracy: 0.7642\n",
            "Epoch 446/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7886\n",
            "Epoch 447/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.4818 - val_accuracy: 0.7805\n",
            "Epoch 448/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7800 - val_loss: 0.4688 - val_accuracy: 0.7886\n",
            "Epoch 449/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7862 - val_loss: 0.4674 - val_accuracy: 0.7642\n",
            "Epoch 450/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7800 - val_loss: 0.4845 - val_accuracy: 0.7886\n",
            "Epoch 451/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7821 - val_loss: 0.4705 - val_accuracy: 0.7642\n",
            "Epoch 452/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7719 - val_loss: 0.5168 - val_accuracy: 0.7967\n",
            "Epoch 453/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7841 - val_loss: 0.5056 - val_accuracy: 0.7886\n",
            "Epoch 454/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4701 - val_accuracy: 0.7805\n",
            "Epoch 455/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7739 - val_loss: 0.4691 - val_accuracy: 0.7642\n",
            "Epoch 456/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8065 - val_loss: 0.4754 - val_accuracy: 0.7724\n",
            "Epoch 457/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7821 - val_loss: 0.4710 - val_accuracy: 0.7805\n",
            "Epoch 458/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4792 - val_accuracy: 0.7724\n",
            "Epoch 459/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4911 - val_accuracy: 0.7805\n",
            "Epoch 460/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.4721 - val_accuracy: 0.7724\n",
            "Epoch 461/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7821 - val_loss: 0.4691 - val_accuracy: 0.7561\n",
            "Epoch 462/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7821 - val_loss: 0.4741 - val_accuracy: 0.7724\n",
            "Epoch 463/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7780 - val_loss: 0.4679 - val_accuracy: 0.7642\n",
            "Epoch 464/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7862 - val_loss: 0.4911 - val_accuracy: 0.7724\n",
            "Epoch 465/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7862 - val_loss: 0.4973 - val_accuracy: 0.7886\n",
            "Epoch 466/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7800 - val_loss: 0.4765 - val_accuracy: 0.7480\n",
            "Epoch 467/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7800 - val_loss: 0.4717 - val_accuracy: 0.7480\n",
            "Epoch 468/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8004 - val_loss: 0.4702 - val_accuracy: 0.7886\n",
            "Epoch 469/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7862 - val_loss: 0.5224 - val_accuracy: 0.7886\n",
            "Epoch 470/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7800 - val_loss: 0.4685 - val_accuracy: 0.7805\n",
            "Epoch 471/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7800 - val_loss: 0.4742 - val_accuracy: 0.7805\n",
            "Epoch 472/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7862 - val_loss: 0.4677 - val_accuracy: 0.7805\n",
            "Epoch 473/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7780 - val_loss: 0.4686 - val_accuracy: 0.7886\n",
            "Epoch 474/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7967\n",
            "Epoch 475/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7821 - val_loss: 0.4676 - val_accuracy: 0.7724\n",
            "Epoch 476/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8024 - val_loss: 0.4696 - val_accuracy: 0.7480\n",
            "Epoch 477/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7780 - val_loss: 0.4713 - val_accuracy: 0.7724\n",
            "Epoch 478/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7800 - val_loss: 0.4716 - val_accuracy: 0.7480\n",
            "Epoch 479/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7923 - val_loss: 0.4920 - val_accuracy: 0.7886\n",
            "Epoch 480/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7821 - val_loss: 0.4702 - val_accuracy: 0.7480\n",
            "Epoch 481/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7943 - val_loss: 0.4687 - val_accuracy: 0.7642\n",
            "Epoch 482/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7821 - val_loss: 0.4944 - val_accuracy: 0.7805\n",
            "Epoch 483/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7739 - val_loss: 0.4682 - val_accuracy: 0.7642\n",
            "Epoch 484/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7780 - val_loss: 0.4741 - val_accuracy: 0.7480\n",
            "Epoch 485/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7699 - val_loss: 0.4692 - val_accuracy: 0.7561\n",
            "Epoch 486/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7943 - val_loss: 0.5004 - val_accuracy: 0.7805\n",
            "Epoch 487/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7923 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 488/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7963 - val_loss: 0.4737 - val_accuracy: 0.7561\n",
            "Epoch 489/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.4688 - val_accuracy: 0.7642\n",
            "Epoch 490/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7984 - val_loss: 0.4697 - val_accuracy: 0.7561\n",
            "Epoch 491/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4739 - val_accuracy: 0.7480\n",
            "Epoch 492/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7699 - val_loss: 0.4728 - val_accuracy: 0.7724\n",
            "Epoch 493/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4742 - val_accuracy: 0.7561\n",
            "Epoch 494/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7739 - val_loss: 0.4754 - val_accuracy: 0.7561\n",
            "Epoch 495/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7841 - val_loss: 0.5237 - val_accuracy: 0.7967\n",
            "Epoch 496/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.4715 - val_accuracy: 0.7805\n",
            "Epoch 497/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7821 - val_loss: 0.4745 - val_accuracy: 0.7886\n",
            "Epoch 498/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8004 - val_loss: 0.4946 - val_accuracy: 0.7724\n",
            "Epoch 499/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7862 - val_loss: 0.4722 - val_accuracy: 0.7561\n",
            "Epoch 500/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7841 - val_loss: 0.4673 - val_accuracy: 0.7724\n",
            "Epoch 501/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.5317 - val_accuracy: 0.7967\n",
            "Epoch 502/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7800 - val_loss: 0.4703 - val_accuracy: 0.7480\n",
            "Epoch 503/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7862 - val_loss: 0.4688 - val_accuracy: 0.7886\n",
            "Epoch 504/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7780 - val_loss: 0.4716 - val_accuracy: 0.7886\n",
            "Epoch 505/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7902 - val_loss: 0.4744 - val_accuracy: 0.7561\n",
            "Epoch 506/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7923 - val_loss: 0.4683 - val_accuracy: 0.7886\n",
            "Epoch 507/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7800 - val_loss: 0.4707 - val_accuracy: 0.7480\n",
            "Epoch 508/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.4733 - val_accuracy: 0.7480\n",
            "Epoch 509/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7821 - val_loss: 0.4826 - val_accuracy: 0.7480\n",
            "Epoch 510/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7943 - val_loss: 0.4887 - val_accuracy: 0.7724\n",
            "Epoch 511/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7902 - val_loss: 0.4754 - val_accuracy: 0.7805\n",
            "Epoch 512/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7805\n",
            "Epoch 513/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4841 - val_accuracy: 0.7561\n",
            "Epoch 514/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7805\n",
            "Epoch 515/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7739 - val_loss: 0.4865 - val_accuracy: 0.7561\n",
            "Epoch 516/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7800 - val_loss: 0.4695 - val_accuracy: 0.7724\n",
            "Epoch 517/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7902 - val_loss: 0.4702 - val_accuracy: 0.7642\n",
            "Epoch 518/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7699 - val_loss: 0.4820 - val_accuracy: 0.7561\n",
            "Epoch 519/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7862 - val_loss: 0.4766 - val_accuracy: 0.7480\n",
            "Epoch 520/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7658 - val_loss: 0.4842 - val_accuracy: 0.7561\n",
            "Epoch 521/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7841 - val_loss: 0.4826 - val_accuracy: 0.7561\n",
            "Epoch 522/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4760 - val_accuracy: 0.7561\n",
            "Epoch 523/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7923 - val_loss: 0.4882 - val_accuracy: 0.7724\n",
            "Epoch 524/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7902 - val_loss: 0.4853 - val_accuracy: 0.7561\n",
            "Epoch 525/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7923 - val_loss: 0.4815 - val_accuracy: 0.7561\n",
            "Epoch 526/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7821 - val_loss: 0.5205 - val_accuracy: 0.7805\n",
            "Epoch 527/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7902 - val_loss: 0.4942 - val_accuracy: 0.7561\n",
            "Epoch 528/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7963 - val_loss: 0.4744 - val_accuracy: 0.7805\n",
            "Epoch 529/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7862 - val_loss: 0.4757 - val_accuracy: 0.7480\n",
            "Epoch 530/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8004 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 531/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7902 - val_loss: 0.4765 - val_accuracy: 0.7561\n",
            "Epoch 532/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7800 - val_loss: 0.4815 - val_accuracy: 0.7480\n",
            "Epoch 533/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7821 - val_loss: 0.4936 - val_accuracy: 0.7724\n",
            "Epoch 534/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7699 - val_loss: 0.4775 - val_accuracy: 0.7642\n",
            "Epoch 535/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7862 - val_loss: 0.5021 - val_accuracy: 0.7805\n",
            "Epoch 536/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7862 - val_loss: 0.4841 - val_accuracy: 0.7480\n",
            "Epoch 537/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7923 - val_loss: 0.4934 - val_accuracy: 0.7805\n",
            "Epoch 538/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8024 - val_loss: 0.4733 - val_accuracy: 0.7724\n",
            "Epoch 539/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8065 - val_loss: 0.4843 - val_accuracy: 0.7561\n",
            "Epoch 540/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7902 - val_loss: 0.4751 - val_accuracy: 0.7805\n",
            "Epoch 541/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7841 - val_loss: 0.4778 - val_accuracy: 0.7886\n",
            "Epoch 542/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4776 - val_accuracy: 0.7561\n",
            "Epoch 543/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4756 - val_accuracy: 0.7805\n",
            "Epoch 544/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4832 - val_accuracy: 0.7561\n",
            "Epoch 545/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7561\n",
            "Epoch 546/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7963 - val_loss: 0.5052 - val_accuracy: 0.7805\n",
            "Epoch 547/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7800 - val_loss: 0.4766 - val_accuracy: 0.7642\n",
            "Epoch 548/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.4866 - val_accuracy: 0.7642\n",
            "Epoch 549/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7862 - val_loss: 0.4770 - val_accuracy: 0.7561\n",
            "Epoch 550/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7862 - val_loss: 0.5019 - val_accuracy: 0.7642\n",
            "Epoch 551/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7862 - val_loss: 0.4840 - val_accuracy: 0.7805\n",
            "Epoch 552/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7841 - val_loss: 0.4843 - val_accuracy: 0.7480\n",
            "Epoch 553/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7841 - val_loss: 0.4905 - val_accuracy: 0.7886\n",
            "Epoch 554/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4777 - val_accuracy: 0.7724\n",
            "Epoch 555/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7902 - val_loss: 0.4773 - val_accuracy: 0.7805\n",
            "Epoch 556/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7862 - val_loss: 0.4783 - val_accuracy: 0.7642\n",
            "Epoch 557/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7821 - val_loss: 0.4879 - val_accuracy: 0.7642\n",
            "Epoch 558/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.4793 - val_accuracy: 0.7642\n",
            "Epoch 559/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7719 - val_loss: 0.4813 - val_accuracy: 0.7805\n",
            "Epoch 560/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7862 - val_loss: 0.5127 - val_accuracy: 0.7642\n",
            "Epoch 561/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7637 - val_loss: 0.4775 - val_accuracy: 0.7886\n",
            "Epoch 562/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7780 - val_loss: 0.4819 - val_accuracy: 0.7805\n",
            "Epoch 563/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7821 - val_loss: 0.4824 - val_accuracy: 0.7561\n",
            "Epoch 564/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7821 - val_loss: 0.4817 - val_accuracy: 0.7561\n",
            "Epoch 565/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7805\n",
            "Epoch 566/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7902 - val_loss: 0.5116 - val_accuracy: 0.7642\n",
            "Epoch 567/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4837 - val_accuracy: 0.7561\n",
            "Epoch 568/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7739 - val_loss: 0.4789 - val_accuracy: 0.7805\n",
            "Epoch 569/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7984 - val_loss: 0.4826 - val_accuracy: 0.7805\n",
            "Epoch 570/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.4832 - val_accuracy: 0.7805\n",
            "Epoch 571/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7923 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
            "Epoch 572/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7800 - val_loss: 0.4858 - val_accuracy: 0.7480\n",
            "Epoch 573/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7963 - val_loss: 0.4975 - val_accuracy: 0.7724\n",
            "Epoch 574/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7943 - val_loss: 0.4981 - val_accuracy: 0.7724\n",
            "Epoch 575/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7719 - val_loss: 0.5119 - val_accuracy: 0.7805\n",
            "Epoch 576/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7780 - val_loss: 0.4816 - val_accuracy: 0.7561\n",
            "Epoch 577/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7943 - val_loss: 0.4823 - val_accuracy: 0.7886\n",
            "Epoch 578/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7800 - val_loss: 0.5062 - val_accuracy: 0.7724\n",
            "Epoch 579/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7923 - val_loss: 0.4888 - val_accuracy: 0.7561\n",
            "Epoch 580/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7699 - val_loss: 0.4820 - val_accuracy: 0.7561\n",
            "Epoch 581/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7943 - val_loss: 0.4990 - val_accuracy: 0.7561\n",
            "Epoch 582/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7943 - val_loss: 0.4847 - val_accuracy: 0.7724\n",
            "Epoch 583/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7984 - val_loss: 0.4858 - val_accuracy: 0.7724\n",
            "Epoch 584/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7699 - val_loss: 0.4800 - val_accuracy: 0.7805\n",
            "Epoch 585/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7841 - val_loss: 0.4826 - val_accuracy: 0.7886\n",
            "Epoch 586/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7923 - val_loss: 0.4867 - val_accuracy: 0.7805\n",
            "Epoch 587/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7739 - val_loss: 0.4834 - val_accuracy: 0.7561\n",
            "Epoch 588/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7902 - val_loss: 0.5100 - val_accuracy: 0.7805\n",
            "Epoch 589/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7841 - val_loss: 0.4799 - val_accuracy: 0.7805\n",
            "Epoch 590/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7805\n",
            "Epoch 591/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7561\n",
            "Epoch 592/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7963 - val_loss: 0.4858 - val_accuracy: 0.7724\n",
            "Epoch 593/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7984 - val_loss: 0.4956 - val_accuracy: 0.7561\n",
            "Epoch 594/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7805\n",
            "Epoch 595/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7800 - val_loss: 0.4856 - val_accuracy: 0.7724\n",
            "Epoch 596/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7862 - val_loss: 0.5288 - val_accuracy: 0.7805\n",
            "Epoch 597/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7805\n",
            "Epoch 598/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.4847 - val_accuracy: 0.7724\n",
            "Epoch 599/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7678 - val_loss: 0.5403 - val_accuracy: 0.7805\n",
            "Epoch 600/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7984 - val_loss: 0.4847 - val_accuracy: 0.7561\n",
            "Epoch 601/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8024 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
            "Epoch 602/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4862 - val_accuracy: 0.7805\n",
            "Epoch 603/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7902 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
            "Epoch 604/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7719 - val_loss: 0.5040 - val_accuracy: 0.7724\n",
            "Epoch 605/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7862 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
            "Epoch 606/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7800 - val_loss: 0.4837 - val_accuracy: 0.7642\n",
            "Epoch 607/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7821 - val_loss: 0.4845 - val_accuracy: 0.7480\n",
            "Epoch 608/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7841 - val_loss: 0.4877 - val_accuracy: 0.7642\n",
            "Epoch 609/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7902 - val_loss: 0.4881 - val_accuracy: 0.7642\n",
            "Epoch 610/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7800 - val_loss: 0.5485 - val_accuracy: 0.7805\n",
            "Epoch 611/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7821 - val_loss: 0.4889 - val_accuracy: 0.7480\n",
            "Epoch 612/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7739 - val_loss: 0.4867 - val_accuracy: 0.7561\n",
            "Epoch 613/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7943 - val_loss: 0.4841 - val_accuracy: 0.7724\n",
            "Epoch 614/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7963 - val_loss: 0.4883 - val_accuracy: 0.7561\n",
            "Epoch 615/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7923 - val_loss: 0.4930 - val_accuracy: 0.7561\n",
            "Epoch 616/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7886\n",
            "Epoch 617/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7576 - val_loss: 0.4834 - val_accuracy: 0.7805\n",
            "Epoch 618/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7739 - val_loss: 0.4846 - val_accuracy: 0.7805\n",
            "Epoch 619/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7902 - val_loss: 0.4844 - val_accuracy: 0.7642\n",
            "Epoch 620/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7719 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
            "Epoch 621/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7724\n",
            "Epoch 622/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7943 - val_loss: 0.5158 - val_accuracy: 0.7642\n",
            "Epoch 623/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4971 - val_accuracy: 0.7561\n",
            "Epoch 624/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7943 - val_loss: 0.4885 - val_accuracy: 0.7805\n",
            "Epoch 625/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7862 - val_loss: 0.5188 - val_accuracy: 0.7805\n",
            "Epoch 626/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7780 - val_loss: 0.4889 - val_accuracy: 0.7480\n",
            "Epoch 627/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7780 - val_loss: 0.4871 - val_accuracy: 0.7724\n",
            "Epoch 628/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7841 - val_loss: 0.4849 - val_accuracy: 0.7724\n",
            "Epoch 629/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7943 - val_loss: 0.4863 - val_accuracy: 0.7805\n",
            "Epoch 630/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7862 - val_loss: 0.5248 - val_accuracy: 0.7642\n",
            "Epoch 631/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7841 - val_loss: 0.4853 - val_accuracy: 0.7805\n",
            "Epoch 632/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7984 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
            "Epoch 633/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7821 - val_loss: 0.4914 - val_accuracy: 0.7642\n",
            "Epoch 634/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7739 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 635/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7699 - val_loss: 0.4869 - val_accuracy: 0.7724\n",
            "Epoch 636/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7902 - val_loss: 0.4869 - val_accuracy: 0.7724\n",
            "Epoch 637/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7862 - val_loss: 0.4895 - val_accuracy: 0.7724\n",
            "Epoch 638/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7561\n",
            "Epoch 639/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7841 - val_loss: 0.4907 - val_accuracy: 0.7805\n",
            "Epoch 640/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8045 - val_loss: 0.4898 - val_accuracy: 0.7561\n",
            "Epoch 641/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7821 - val_loss: 0.4886 - val_accuracy: 0.7480\n",
            "Epoch 642/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7821 - val_loss: 0.4960 - val_accuracy: 0.7642\n",
            "Epoch 643/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7841 - val_loss: 0.5318 - val_accuracy: 0.7805\n",
            "Epoch 644/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7800 - val_loss: 0.4899 - val_accuracy: 0.7561\n",
            "Epoch 645/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7739 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
            "Epoch 646/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7841 - val_loss: 0.5175 - val_accuracy: 0.7642\n",
            "Epoch 647/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7480\n",
            "Epoch 648/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7841 - val_loss: 0.4992 - val_accuracy: 0.7642\n",
            "Epoch 649/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7800 - val_loss: 0.4913 - val_accuracy: 0.7805\n",
            "Epoch 650/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7739 - val_loss: 0.4979 - val_accuracy: 0.7561\n",
            "Epoch 651/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7800 - val_loss: 0.4875 - val_accuracy: 0.7561\n",
            "Epoch 652/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7841 - val_loss: 0.4886 - val_accuracy: 0.7724\n",
            "Epoch 653/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7780 - val_loss: 0.4874 - val_accuracy: 0.7724\n",
            "Epoch 654/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7841 - val_loss: 0.4904 - val_accuracy: 0.7642\n",
            "Epoch 655/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7984 - val_loss: 0.4943 - val_accuracy: 0.7642\n",
            "Epoch 656/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7800 - val_loss: 0.4964 - val_accuracy: 0.7398\n",
            "Epoch 657/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.5135 - val_accuracy: 0.7724\n",
            "Epoch 658/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7739 - val_loss: 0.5044 - val_accuracy: 0.7561\n",
            "Epoch 659/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7963 - val_loss: 0.4943 - val_accuracy: 0.7724\n",
            "Epoch 660/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7862 - val_loss: 0.4945 - val_accuracy: 0.7642\n",
            "Epoch 661/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7862 - val_loss: 0.4946 - val_accuracy: 0.7724\n",
            "Epoch 662/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7841 - val_loss: 0.5057 - val_accuracy: 0.7642\n",
            "Epoch 663/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7561\n",
            "Epoch 664/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7780 - val_loss: 0.5034 - val_accuracy: 0.7561\n",
            "Epoch 665/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7943 - val_loss: 0.4929 - val_accuracy: 0.7642\n",
            "Epoch 666/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7821 - val_loss: 0.4941 - val_accuracy: 0.7642\n",
            "Epoch 667/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7780 - val_loss: 0.5009 - val_accuracy: 0.7724\n",
            "Epoch 668/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7800 - val_loss: 0.4942 - val_accuracy: 0.7561\n",
            "Epoch 669/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7800 - val_loss: 0.4993 - val_accuracy: 0.7724\n",
            "Epoch 670/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7862 - val_loss: 0.5002 - val_accuracy: 0.7805\n",
            "Epoch 671/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7821 - val_loss: 0.4959 - val_accuracy: 0.7561\n",
            "Epoch 672/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7841 - val_loss: 0.4984 - val_accuracy: 0.7561\n",
            "Epoch 673/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7963 - val_loss: 0.5051 - val_accuracy: 0.7561\n",
            "Epoch 674/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8024 - val_loss: 0.4931 - val_accuracy: 0.7561\n",
            "Epoch 675/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7963 - val_loss: 0.5570 - val_accuracy: 0.7886\n",
            "Epoch 676/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7841 - val_loss: 0.5045 - val_accuracy: 0.7561\n",
            "Epoch 677/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7943 - val_loss: 0.4910 - val_accuracy: 0.7724\n",
            "Epoch 678/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7821 - val_loss: 0.5057 - val_accuracy: 0.7561\n",
            "Epoch 679/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4939 - val_accuracy: 0.7724\n",
            "Epoch 680/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7800 - val_loss: 0.5137 - val_accuracy: 0.7561\n",
            "Epoch 681/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7923 - val_loss: 0.5019 - val_accuracy: 0.7561\n",
            "Epoch 682/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7642\n",
            "Epoch 683/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7800 - val_loss: 0.5236 - val_accuracy: 0.7642\n",
            "Epoch 684/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7963 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 685/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8106 - val_loss: 0.4958 - val_accuracy: 0.7561\n",
            "Epoch 686/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7821 - val_loss: 0.4960 - val_accuracy: 0.7642\n",
            "Epoch 687/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4969 - val_accuracy: 0.7724\n",
            "Epoch 688/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7923 - val_loss: 0.5045 - val_accuracy: 0.7561\n",
            "Epoch 689/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7739 - val_loss: 0.5012 - val_accuracy: 0.7480\n",
            "Epoch 690/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7984 - val_loss: 0.4994 - val_accuracy: 0.7642\n",
            "Epoch 691/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7719 - val_loss: 0.4952 - val_accuracy: 0.7642\n",
            "Epoch 692/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7642\n",
            "Epoch 693/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8045 - val_loss: 0.5034 - val_accuracy: 0.7642\n",
            "Epoch 694/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7943 - val_loss: 0.4987 - val_accuracy: 0.7561\n",
            "Epoch 695/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7862 - val_loss: 0.4926 - val_accuracy: 0.7642\n",
            "Epoch 696/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7642\n",
            "Epoch 697/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7780 - val_loss: 0.5284 - val_accuracy: 0.7561\n",
            "Epoch 698/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7862 - val_loss: 0.4937 - val_accuracy: 0.7642\n",
            "Epoch 699/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7800 - val_loss: 0.5098 - val_accuracy: 0.7561\n",
            "Epoch 700/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7902 - val_loss: 0.5190 - val_accuracy: 0.7642\n",
            "Epoch 701/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7862 - val_loss: 0.5662 - val_accuracy: 0.7805\n",
            "Epoch 702/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7902 - val_loss: 0.5018 - val_accuracy: 0.7561\n",
            "Epoch 703/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7923 - val_loss: 0.4961 - val_accuracy: 0.7561\n",
            "Epoch 704/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7902 - val_loss: 0.5006 - val_accuracy: 0.7642\n",
            "Epoch 705/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7719 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
            "Epoch 706/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7719 - val_loss: 0.4965 - val_accuracy: 0.7480\n",
            "Epoch 707/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7862 - val_loss: 0.4930 - val_accuracy: 0.7642\n",
            "Epoch 708/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7821 - val_loss: 0.4937 - val_accuracy: 0.7805\n",
            "Epoch 709/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7561\n",
            "Epoch 710/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 711/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7821 - val_loss: 0.5147 - val_accuracy: 0.7561\n",
            "Epoch 712/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7902 - val_loss: 0.4942 - val_accuracy: 0.7642\n",
            "Epoch 713/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7821 - val_loss: 0.4929 - val_accuracy: 0.7561\n",
            "Epoch 714/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7841 - val_loss: 0.5262 - val_accuracy: 0.7642\n",
            "Epoch 715/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7902 - val_loss: 0.4985 - val_accuracy: 0.7642\n",
            "Epoch 716/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7841 - val_loss: 0.4959 - val_accuracy: 0.7480\n",
            "Epoch 717/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.5540 - val_accuracy: 0.7805\n",
            "Epoch 718/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7780 - val_loss: 0.5171 - val_accuracy: 0.7805\n",
            "Epoch 719/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7923 - val_loss: 0.4928 - val_accuracy: 0.7724\n",
            "Epoch 720/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7760 - val_loss: 0.5318 - val_accuracy: 0.7642\n",
            "Epoch 721/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7902 - val_loss: 0.4974 - val_accuracy: 0.7642\n",
            "Epoch 722/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7841 - val_loss: 0.5065 - val_accuracy: 0.7561\n",
            "Epoch 723/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7902 - val_loss: 0.5003 - val_accuracy: 0.7642\n",
            "Epoch 724/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5290 - val_accuracy: 0.7642\n",
            "Epoch 725/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7699 - val_loss: 0.4965 - val_accuracy: 0.7561\n",
            "Epoch 726/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7719 - val_loss: 0.4978 - val_accuracy: 0.7642\n",
            "Epoch 727/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7780 - val_loss: 0.5042 - val_accuracy: 0.7642\n",
            "Epoch 728/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7943 - val_loss: 0.4977 - val_accuracy: 0.7724\n",
            "Epoch 729/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7739 - val_loss: 0.5052 - val_accuracy: 0.7642\n",
            "Epoch 730/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7984 - val_loss: 0.4977 - val_accuracy: 0.7642\n",
            "Epoch 731/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7902 - val_loss: 0.5058 - val_accuracy: 0.7642\n",
            "Epoch 732/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8024 - val_loss: 0.4920 - val_accuracy: 0.7724\n",
            "Epoch 733/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7841 - val_loss: 0.4932 - val_accuracy: 0.7480\n",
            "Epoch 734/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7923 - val_loss: 0.4946 - val_accuracy: 0.7642\n",
            "Epoch 735/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7841 - val_loss: 0.4939 - val_accuracy: 0.7480\n",
            "Epoch 736/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7561\n",
            "Epoch 737/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7862 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 738/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7821 - val_loss: 0.4942 - val_accuracy: 0.7561\n",
            "Epoch 739/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7780 - val_loss: 0.5102 - val_accuracy: 0.7805\n",
            "Epoch 740/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7800 - val_loss: 0.5177 - val_accuracy: 0.7724\n",
            "Epoch 741/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7561\n",
            "Epoch 742/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7923 - val_loss: 0.5018 - val_accuracy: 0.7724\n",
            "Epoch 743/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.5222 - val_accuracy: 0.7642\n",
            "Epoch 744/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7780 - val_loss: 0.4955 - val_accuracy: 0.7480\n",
            "Epoch 745/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7780 - val_loss: 0.5006 - val_accuracy: 0.7561\n",
            "Epoch 746/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7821 - val_loss: 0.4995 - val_accuracy: 0.7561\n",
            "Epoch 747/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7821 - val_loss: 0.4950 - val_accuracy: 0.7724\n",
            "Epoch 748/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7780 - val_loss: 0.5382 - val_accuracy: 0.7561\n",
            "Epoch 749/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7841 - val_loss: 0.4945 - val_accuracy: 0.7642\n",
            "Epoch 750/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7719 - val_loss: 0.5053 - val_accuracy: 0.7642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "69dOEi6HAiXT",
        "outputId": "d6fb9638-bb40-4000-9a06-d57a8178628c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "8be484dd-fead-4da6-cb0e-d99ef8fa27fe"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "eed97bc1-d1cd-4fa5-f3e2-518eb00ee095"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5125998 , 0.48740014]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "2676fb72-cbd9-47a7-d037-de57ebaaf57a"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}